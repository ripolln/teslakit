{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "... ***CURRENTLY UNDER DEVELOPMENT*** ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain synthetic DWTs timeseries\n",
    "\n",
    "inputs required: \n",
    "  * Historical DWTs\n",
    "  * Historical AWT and IWT\n",
    "  * Synthetic timeseries of AWT and IWT\n",
    "  \n",
    "in this notebook:\n",
    "  * Fit the ALR model of DWT based on seasonality,and  AWT and IWT timeseries\n",
    "  * Generate *n* simulations of 1000 years of DWTs timeseries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Workflow:\n",
    "\n",
    "<div>\n",
    "<img src=\"resources/nb01_11.png\" width=\"400px\">\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "Simulating sequencing and persistence of synthetic DWTs is accomplished with an autoregressive logistic model (ALR). ALR models are simultaneously able to account for covariates varying at different timescales as well as the autocorrelation of those covariates at different orders (Guanche et al., 2013; Antolinez et al., 2015). In this sense, the AWT, seasonality, IWT, as well as the ordering (transitions between DWTs) and duration (persistence within a DWT) can all be accounted for within a single framework to make a categorical decision of what the weather pattern should be on any given day. Mathematically, the model is represented as:\n",
    "\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Prob$(Y_t=i|Y_{t-1},...,Y_{t-e},X_t)$ = \n",
    " \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$= {{\\exp{\\large (}\\beta_{0,i} + \\beta_{1,i}\\cos \\omega t + \\beta_{2,i}\\sin \\omega t + \\sum\\limits_{j=1}^{3}\\beta_{j,i}^{awt} APC_j(t) + \\sum\\limits_{j=1}^{2}\\beta_{j,i}^{iwt} IPC_j(t) + \\sum\\limits_{j=1}^e Y_{t-j\\gamma j,i}{\\large )}} \\over {\\sum\\limits_{k=1}^{n_{DWT}} \\exp{\\large (}\\beta_{0,k} + \\beta_{1,k}\\cos \\omega t + \\beta_{2,k}\\sin \\omega t + \\sum\\limits_{j=1}^{3}\\beta_{j,k}^{awt} APC_j(t) + \\sum\\limits_{j=1}^{2}\\beta_{j,k}^{iwt} IPC_j(t) + \\sum\\limits_{j=1}^e Y_{t-j\\gamma j,k}{\\large )}}}$;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</center>\n",
    " \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$\\forall i = 1,...,n_{ss}$\n",
    " \n",
    "where  $\\beta_{1,i}$ and $\\beta_{2,i}$ covariates account for the seasonal probabilites of each DWT. Covariates $\\beta_{j,k}^{awt} APC_j(t)$ account for each weather type’s probability associated with the leading three principle components used to create the AWTs, covariates $\\beta_{j,k}^{iwt} IPC_j(t)$ account for the leading two principle components of the MJO, and $Y_{t-j}$ represents the DWT of the previous j-states, and $\\beta_{j,i}$  is the parameter associated with the previous j-state, and the order e corresponds to the number of previous states that influence the actual DWT.\n",
    "Each of these covariates was found to be statistically significant by the likelihood ratio (Guanche et al. 2014), where inclusion of a covariate required an improvement in prediction beyond a penalty associated with the added degrees of freedom. An iterative method began with the best univariate model (seasonality) and added each covariate in a pair-wise fashion to determine the next best model (seasonality + $APC_1$), continuing this process until all covariates were added. \n",
    "\n",
    "The model performance is evaluated at the end of the notebook by means of comparison historical and simulated probabilities of occurrence of the 42 DWTs during a perpetual year, the transition probabilities between DWTs and finally seasonal and conditional probabilities of occurrance of DWT to AWT and IWT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lcag075\\AppData\\Local\\Continuum\\anaconda2\\envs\\teslakit\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# common\n",
    "import os\n",
    "import os.path as op\n",
    "\n",
    "# pip\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "# DEV: override installed teslakit\n",
    "import sys\n",
    "sys.path.insert(0, op.join(os.path.abspath(''), '..', '..', '..'))\n",
    "\n",
    "# teslakit \n",
    "from teslakit.database import Database\n",
    "from teslakit.alr import ALR_WRP\n",
    "from teslakit.util.time_operations import xds_reindex_daily, xds_common_dates_daily\n",
    "\n",
    "from teslakit.plotting.estela import Plot_DWTs_Probs\n",
    "from teslakit.plotting.wts import Plot_Probs_WT_WT, Plot_Probs_WT_WT_anomaly\n",
    "from teslakit.plotting.waves import Plot_Waves_DWTs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Database and Site parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------\n",
    "# Teslakit database\n",
    "\n",
    "p_data = r'C:\\Users\\lcag075\\Dropbox\\MAJURO-teslakit\\teslakit\\DATA'\n",
    "db = Database(p_data)\n",
    "\n",
    "# set site\n",
    "db.SetSite('MAJURO')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------\n",
    "# load data and set parameters\n",
    "\n",
    "MJO_fit = db.Load_MJO_hist()           # historical MJO\n",
    "KMA_fit = db.Load_ESTELA_KMA()         # ESTELA + TCs Predictor\n",
    "PCs_all = db.Load_SST_PCA()            # SST PCs (annual)\n",
    "\n",
    "MJO_sim_all = db.Load_MJO_sim()        # MJO simulations (daily)\n",
    "PCs_sim_all = db.Load_SST_PCs_sim_d()  # SST PCs simulations (daily)\n",
    "\n",
    "# ALR fit parameters\n",
    "alr_num_clusters = 42\n",
    "alr_markov_order = 3\n",
    "alr_seasonality = [2, 4]\n",
    "\n",
    "# ALR simulation\n",
    "num_sims = 100  # one simulation for each simulated MJO, SST \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## ESTELA Predictor - Autoregressive Logistic Regression Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (time: 14343)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1979-01-01 1979-01-02 ... 2018-04-08\n",
      "Data variables:\n",
      "    phase    (time) int64 ...\n",
      "    rmm1     (time) float64 ...\n",
      "    rmm2     (time) float64 ...\n",
      "    mjo      (time) float64 ...\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (time: 49674)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1880-06-01 1880-06-02 ... 2016-06-01\n",
      "Data variables:\n",
      "    PC1      (time) float64 7.972 7.972 7.972 7.972 ... 55.53 55.53 55.53 -7.664\n",
      "    PC2      (time) float64 1.668 1.668 1.668 1.668 ... 7.856 7.856 7.856 35.98\n",
      "    PC3      (time) float64 -7.23 -7.23 -7.23 -7.23 ... 3.494 3.494 3.494 -9.33\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------\n",
    "# Data used to FIT ALR model and preprocess: \n",
    "\n",
    "# KMA: bmus (daily) (use sorted_bmus_storms, add 1 to get 1-42 bmus set)\n",
    "BMUS_fit = xr.Dataset(\n",
    "    {\n",
    "        'bmus':(('time',), KMA_fit['sorted_bmus_storms'].values[:] + 1),\n",
    "    },\n",
    "    coords = {'time': KMA_fit.time.values[:]}\n",
    ")\n",
    "\n",
    "\n",
    "# MJO: rmm1, rmm2 (daily)\n",
    "print(MJO_fit)\n",
    "\n",
    "# SST: PCs (annual)\n",
    "sst_PCs = PCs_all.PCs.values[:]\n",
    "PCs_fit = xr.Dataset(\n",
    "    {\n",
    "        'PC1': (('time',), sst_PCs[:,0]),\n",
    "        'PC2': (('time',), sst_PCs[:,1]),\n",
    "        'PC3': (('time',), sst_PCs[:,2]),\n",
    "    },\n",
    "    coords = {'time': PCs_all.time.values[:]}\n",
    ")\n",
    "\n",
    "# reindex annual data to daily data\n",
    "PCs_fit = xds_reindex_daily(PCs_fit)\n",
    "print(PCs_fit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:    (n_covariates: 5, time: 13268)\n",
      "Coordinates:\n",
      "  * time       (time) datetime64[ns] 1980-02-04 1980-02-05 ... 2016-06-01\n",
      "Dimensions without coordinates: n_covariates\n",
      "Data variables:\n",
      "    cov_norm   (time, n_covariates) float64 0.442 0.4045 ... -0.938 0.3304\n",
      "    cov_names  (n_covariates) <U4 'PC1' 'PC2' 'PC3' 'MJO1' 'MJO2'\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------\n",
    "# Mount covariates matrix (model fit: BMUS_fit, MJO_fit, PCs_fit)\n",
    "\n",
    "# covariates_fit dates\n",
    "d_fit = xds_common_dates_daily([MJO_fit, PCs_fit, BMUS_fit])\n",
    "\n",
    "# KMA dates\n",
    "BMUS_fit = BMUS_fit.sel(time = slice(d_fit[0], d_fit[-1]))\n",
    "\n",
    "# PCs covars \n",
    "cov_PCs = PCs_fit.sel(time = slice(d_fit[0], d_fit[-1]))\n",
    "cov_1 = cov_PCs.PC1.values.reshape(-1,1)\n",
    "cov_2 = cov_PCs.PC2.values.reshape(-1,1)\n",
    "cov_3 = cov_PCs.PC3.values.reshape(-1,1)\n",
    "\n",
    "# MJO covars\n",
    "cov_MJO = MJO_fit.sel(time = slice(d_fit[0], d_fit[-1]))\n",
    "cov_4 = cov_MJO.rmm1.values.reshape(-1,1)\n",
    "cov_5 = cov_MJO.rmm2.values.reshape(-1,1)\n",
    "\n",
    "# join covars \n",
    "cov_T = np.hstack((cov_1, cov_2, cov_3, cov_4, cov_5))\n",
    "\n",
    "# normalize\n",
    "cov_norm_fit = (cov_T - cov_T.mean(axis=0)) / cov_T.std(axis=0)\n",
    "cov_fit = xr.Dataset(\n",
    "    {\n",
    "        'cov_norm': (('time','n_covariates'), cov_norm_fit),\n",
    "        'cov_names': (('n_covariates',), ['PC1','PC2','PC3','MJO1','MJO2']),\n",
    "    },\n",
    "    coords = {'time': d_fit}\n",
    ")\n",
    "print(cov_fit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting autoregressive logistic model ...\n",
      "Optimization done in 74.21 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------\n",
    "# Autoregressive Logistic Regression\n",
    "\n",
    "# model fit: BMUS_fit, cov_fit, num_clusters\n",
    "# model sim: cov_sim, sim_num, sim_years\n",
    "\n",
    "# ALR terms\n",
    "d_terms_settings = {\n",
    "    'mk_order'  : alr_markov_order,\n",
    "    'constant' : True,\n",
    "    'long_term' : False,\n",
    "    'seasonality': (True, alr_seasonality),\n",
    "    'covariates': (True, cov_fit),\n",
    "}\n",
    "\n",
    "# ALR wrapper\n",
    "ALRW = ALR_WRP(db.paths.site.ESTELA.alrw)\n",
    "ALRW.SetFitData(alr_num_clusters, BMUS_fit, d_terms_settings)\n",
    "\n",
    "# ALR model fitting\n",
    "ALRW.FitModel(max_iter=50000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning - statsmodels MNLogit could not provide p-values\n"
     ]
    }
   ],
   "source": [
    "# Plot model p-values and params\n",
    "ALRW.Report_Fit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## ESTELA Predictor - Autoregressive Logistic Regression Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:     (n_covariates: 5, n_sim: 100, time: 365244)\n",
      "Coordinates:\n",
      "  * time        (time) object 2000-01-01 2000-01-02 ... 2999-12-31 3000-01-01\n",
      "Dimensions without coordinates: n_covariates, n_sim\n",
      "Data variables:\n",
      "    cov_values  (n_sim, time, n_covariates) float32 -1.4686646 ... 0.809511\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------\n",
    "# Prepare Covariates for ALR simulations\n",
    "\n",
    "# simulation dates\n",
    "d_sim = xds_common_dates_daily([MJO_sim_all, PCs_sim_all])\n",
    "\n",
    "# join covariates for all MJO, PCs simulations\n",
    "l_cov_sims = []\n",
    "for i in MJO_sim_all.n_sim: \n",
    "\n",
    "    # select simulation\n",
    "    MJO_sim = MJO_sim_all.sel(n_sim=i)\n",
    "    PCs_sim = PCs_sim_all.sel(n_sim=i)\n",
    "\n",
    "    # PCs covar \n",
    "    cov_PCs = PCs_sim.sel(time = slice(d_sim[0], d_sim[-1]))\n",
    "    cov_1 = cov_PCs.PC1.values.reshape(-1,1)\n",
    "    cov_2 = cov_PCs.PC2.values.reshape(-1,1)\n",
    "    cov_3 = cov_PCs.PC3.values.reshape(-1,1)\n",
    "\n",
    "    # MJO covars\n",
    "    cov_MJO = MJO_sim.sel(time = slice(d_sim[0], d_sim[-1]))\n",
    "    cov_4 = cov_MJO.rmm1.values.reshape(-1,1)\n",
    "    cov_5 = cov_MJO.rmm2.values.reshape(-1,1)\n",
    "\n",
    "    # join covars (do not normalize simulation covariates)\n",
    "    cov_T_sim = np.hstack((cov_1, cov_2, cov_3, cov_4, cov_5))\n",
    "    cov_sim = xr.Dataset(\n",
    "        {\n",
    "            'cov_values': (('time','n_covariates'), cov_T_sim),\n",
    "        },\n",
    "        coords = {'time': d_sim}\n",
    "    )\n",
    "    l_cov_sims.append(cov_sim)\n",
    "\n",
    "# use \"n_sim\" name to join covariates (ALR.Simulate() will recognize it)\n",
    "cov_sims = xr.concat(l_cov_sims, dim='n_sim')\n",
    "cov_sims = cov_sims.squeeze()\n",
    "\n",
    "print(cov_sims)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALR model fit   : 1980-02-04 --- 2016-06-01\n",
      "ALR model sim   : 2000-01-01 --- 3000-01-01\n",
      "\n",
      "Launching 100 simulations...\n",
      "\n",
      "Sim. Num. 001 (Covs. 001):  52%|███████████████████████▉                      | 190350/365241 [04:26<07:09, 407.01it/s]"
     ]
    }
   ],
   "source": [
    "# --------------------------------------\n",
    "# Autoregressive Logistic Regression - simulate \n",
    "\n",
    "# launch simulation\n",
    "xds_alr = ALRW.Simulate(num_sims, d_sim, cov_sims)\n",
    "\n",
    "# Store Daily Weather Types\n",
    "DWT_sim = xds_alr.evbmus_sims.to_dataset()\n",
    "db.Save_ESTELA_DWT_sim(DWT_sim)\n",
    "\n",
    "print(DWT_sim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show sim report\n",
    "ALRW.Report_Sim(py_month_ini=6);\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Historical DWTs probabilities (with TCs DWTs)\n",
    "\n",
    "bmus_fit = KMA_fit.sorted_bmus_storms.values[:] + 1\n",
    "dbmus_fit = KMA_fit.time.values[:]\n",
    "\n",
    "Plot_DWTs_Probs(bmus_fit, dbmus_fit, alr_num_clusters);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Simulated DWTs probabilities (with TCs DWTs)\n",
    "\n",
    "bmus_sim = DWT_sim.isel(n_sim=0).evbmus_sims.values[:]\n",
    "dbmus_sim = DWT_sim.time.values[:]\n",
    "\n",
    "Plot_DWTs_Probs(bmus_sim, dbmus_sim, alr_num_clusters);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot AWTs/DWTs Probabilities \n",
    "\n",
    "# clusters to plot (no TCs)\n",
    "n_clusters_AWT = 6\n",
    "n_clusters_DWT = 42\n",
    "n_sim = 0  # simulation to plot\n",
    "\n",
    "# Plot AWTs/DWTs Probs - historical\n",
    "AWT_hist, DWT_hist = db.Load_AWTs_DWTs_Plots_hist()\n",
    "AWT_bmus = AWT_hist.bmus.values[:]\n",
    "DWT_bmus = DWT_hist.bmus.values[:]\n",
    "\n",
    "Plot_Probs_WT_WT(\n",
    "    AWT_bmus, DWT_bmus, n_clusters_AWT, n_clusters_DWT,\n",
    "    wt_colors=True, ttl = 'DWTs Probabilities by AWTs - Historical'\n",
    ");\n",
    "\n",
    "# Plot AWTs/DWTs sim - simulated\n",
    "AWT_sim, DWT_sim = db.Load_AWTs_DWTs_Plots_sim(n_sim=0)\n",
    "AWT_bmus = AWT_sim.bmus.values[:]\n",
    "DWT_bmus = DWT_sim.bmus.values[:]\n",
    "\n",
    "Plot_Probs_WT_WT(\n",
    "    AWT_bmus, DWT_bmus, n_clusters_AWT, n_clusters_DWT,\n",
    "    wt_colors=True, ttl = 'DWTs Probabilities by AWTs - Simulation'\n",
    ");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot DWTs conditional probabilities to each AWT, minus mean probabilities\n",
    "\n",
    "# Plot AWTs/DWTs Probs - historical\n",
    "AWT_hist, DWT_hist = db.Load_AWTs_DWTs_Plots_hist()\n",
    "AWT_bmus = AWT_hist.bmus.values[:]\n",
    "DWT_bmus = DWT_hist.bmus.values[:]\n",
    "\n",
    "Plot_Probs_WT_WT_anomaly(\n",
    "    AWT_bmus, DWT_bmus, n_clusters_AWT, n_clusters_DWT,\n",
    "    wt_colors=True, ttl = 'DWTs anomaly Probabilities by AWTs - Historical'\n",
    ");\n",
    "\n",
    "# Plot AWTs/DWTs sim - simulated\n",
    "AWT_sim, DWT_sim = db.Load_AWTs_DWTs_Plots_sim(n_sim=0)\n",
    "AWT_bmus = AWT_sim.bmus.values[:]\n",
    "DWT_bmus = DWT_sim.bmus.values[:]\n",
    "\n",
    "Plot_Probs_WT_WT_anomaly(\n",
    "    AWT_bmus, DWT_bmus, n_clusters_AWT, n_clusters_DWT,\n",
    "    wt_colors=True, ttl = 'DWTs anomaly Probabilities by AWTs - Simulation'\n",
    ");\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teslakit",
   "language": "python",
   "name": "teslakit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
