{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "... ***CURRENTLY UNDER DEVELOPMENT*** ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HyCReeW runup estimation \n",
    "\n",
    "inputs required: \n",
    "  * Nearshore reconstructed historical storms\n",
    "  * Nearshore reconstructed simulated storms\n",
    "  * Historical water levels\n",
    "  * Synthetic water levels \n",
    "  * **Expected Sea Level Rise the Site (for the intermediate scenario)**\n",
    "\n",
    "    \n",
    "in this notebook:\n",
    "  * HyCReWW runup estimation of historical and synthetic events **taking into account the intermediate SLR scenario**\n",
    "  * Extreme value analysis and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# common\n",
    "import os\n",
    "import os.path as op\n",
    "\n",
    "# pip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "# DEV: override installed teslakit\n",
    "import sys\n",
    "sys.path.insert(0, op.join(os.path.abspath(''), '..', '..', '..', '..'))\n",
    "\n",
    "# teslakit\n",
    "from teslakit.database import Database\n",
    "from teslakit.rbf import RBF_Interpolation\n",
    "from teslakit.mda import Normalize\n",
    "\n",
    "from teslakit.plotting.extremes import Plot_ReturnPeriodValidation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Database and Site parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------\n",
    "# Teslakit database\n",
    "\n",
    "p_data = r'/Users/albacid/Projects/TeslaKit_projects'\n",
    "\n",
    "# offshore\n",
    "db = Database(p_data)\n",
    "db.SetSite('ROI')\n",
    "\n",
    "# climate change - S4\n",
    "db_S4 = Database(p_data)\n",
    "db_S4.SetSite('ROI_CC_S4')\n",
    "\n",
    "\n",
    "# reef characteristics\n",
    "reef_cs = {\n",
    "    'rslope': 0.0505,\n",
    "    'bslope': 0.1667,\n",
    "    'rwidth': 250,\n",
    "    'cf': 0.0105,\n",
    "}\n",
    "\n",
    "\n",
    "# load Hycreww RBF coefficients and sim. variables min. and max.\n",
    "var_lims, rbf_coeffs = db.Load_HYCREWW()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hycreww interpolation \n",
    "\n",
    "def hycreww_runup(var_lims, rbf_coeffs, dset):\n",
    "    '''\n",
    "    Calculates RunUp using hycreww RBFs (level) and linear interpolation (Runup)\n",
    "    \n",
    "    var_lims   - hycreww variables min and max limits\n",
    "    rbf_coeffs - hycreww rbf coefficients\n",
    "    dset       - input dataset (pandas.DataFrame with \"rbf_vns\" columns)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # RBF wave conditions \n",
    "    rbf_hs = [1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5]\n",
    "    rbf_hs_lo = [0.005, 0.025, 0.05, 0.005, 0.025, 0.05, 0.005, 0.025, 0.05, 0.005, 0.025, 0.05, 0.005, 0.025, 0.05 ]\n",
    "    rbf_vns = ['level', 'rslope', 'bslope', 'rwidth', 'cf']\n",
    "    \n",
    "    # RBF parameters\n",
    "    ix_sc = [0, 1, 2, 3, 4]\n",
    "    ix_dr = []\n",
    "    minis = [var_lims[x][0] for x in rbf_vns]\n",
    "    maxis = [var_lims[x][1] for x in rbf_vns]\n",
    "    \n",
    "    \n",
    "    # add reef characteristics\n",
    "    for p in reef_cs.keys():\n",
    "        dset[p] = reef_cs[p]\n",
    "\n",
    "    # discard data outside limits\n",
    "    for vn in var_lims.keys():\n",
    "        dset = dset[(dset[vn] > var_lims[vn][0]) &(dset[vn] < var_lims[vn][1])]\n",
    "    \n",
    "    \n",
    "    # RBF dataset to interpolate\n",
    "    ds_in = dset[rbf_vns]\n",
    "\n",
    "    # normalize data\n",
    "    ds_nm ,_ ,_ = Normalize(ds_in.values, ix_sc, ix_dr, minis=minis, maxis=maxis)\n",
    "\n",
    "    # RBF interpolation (with all cases?)\n",
    "    ru_out = []\n",
    "    for rc in rbf_coeffs:\n",
    "        ro = RBF_Interpolation(rc['constant'], rc['coeff'], rc['nodes'], ds_nm.T)\n",
    "        ru_out.append(ro)\n",
    "    ru_z = np.array(ru_out)\n",
    "    \n",
    "    # RU Linear interpolation (hs, hs_lo -> runup)\n",
    "    RU = []\n",
    "    for c, (_, r) in enumerate(dset.iterrows()):\n",
    "        vq = griddata((rbf_hs, rbf_hs_lo), ru_z[:,c], (r['hs'], r['hs_lo2']), method='linear')\n",
    "        RU.append(vq)\n",
    "    RU = np.array(RU)\n",
    "    \n",
    "    # store runup alongside input data\n",
    "    dset_out = dset.copy()\n",
    "    dset_out['runup'] = dset_out['level'] + RU\n",
    "\n",
    "    return dset_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hycreww RBF Interpolation: Historical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load historical runup\n",
    "out_hist = db.Load_NEARSHORE_RUNUP_HIST()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Hycreww RBF Interpolation: Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:   (scenario: 3, time: 885360)\n",
      "Coordinates:\n",
      "  * time      (time) datetime64[ns] 2000-01-01 ... 2100-12-31T22:58:07.500000256\n",
      "  * scenario  (scenario) float32 0.5 1.0 1.5\n",
      "Data variables:\n",
      "    SLR       (time, scenario) float32 ...\n"
     ]
    }
   ],
   "source": [
    "# Load SLR file\n",
    "\n",
    "SLR = xr.open_dataset(p_data + '/sites/ROI_CC_S4/CLIMATE_CHANGE/SLR.nc')\n",
    "print(SLR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load complete simulations data and nearshore waves\n",
    "\n",
    "n_sims_DWT = 10\n",
    "data_list = db_S4.Load_SIM_Complete_storms(n_sims=n_sims_DWT)\n",
    "waves_list = db_S4.Load_NEARSHORE_RECONSTRUCTION_SIM_storms(n_sims=n_sims_DWT)\n",
    "\n",
    "# iterate storms waves simulations\n",
    "l_sims_CC = []\n",
    "for dd, ww in zip(data_list, waves_list):\n",
    "    \n",
    "    ww = ww.rename_vars({\"Hs\": \"hs\", \"Tp\": \"tp\", 'Dir':'dir'})  # rename vars\n",
    "    ww['hs_lo2'] = ww['hs']/(1.5613*ww['tp']**2)                # calc. hs_lo2\n",
    "    ww['level'] = dd.sel(time=ww.time).level                    # add level\n",
    "    \n",
    "    \n",
    "    # TODO: mean water level in the tidal gauge in the period 1991-2009 for this base level\n",
    "    \n",
    "    \n",
    "    # TODO: \n",
    "    # 1) reshape to 100 yrs length\n",
    "    # 2) SLR from SLR.scenario=1. Add the “parabola” since 2000 to 2100\n",
    "        # ww['level'] = ww['level'] + SLR\n",
    "    # 3) reshape again to 1000 yrs length (¿¿¿¿¿ ?????)\n",
    "    # ww['level'] = ww['level'] + SLR\n",
    "    \n",
    "    \n",
    "    \n",
    "    # calculate runup with hycreww\n",
    "    dset = ww[['hs', 'tp', 'dir', 'level', 'hs_lo2']].to_dataframe()\n",
    "    out_sim = hycreww_runup(var_lims, rbf_coeffs, dset)\n",
    "    \n",
    "    l_sims_CC.append(out_sim)\n",
    "\n",
    "    \n",
    "# store simulation runup\n",
    "db_S4.Save_NEARSHORE_RUNUP_SIM(l_sims_CC)\n",
    "\n",
    "l_sims = db.Load_NEARSHORE_RUNUP_SIM(n_sims=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Methodology Validation: Annual Maxima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# compare historical and simulations runup annual maxima\n",
    "hist_A = out_hist.to_xarray()['runup'].groupby('time.year').max(dim='time')\n",
    "sim_A = xr.concat([x.to_xarray()['runup'].groupby('time.year').max(dim='time') for x in l_sims], 'n_sim')\n",
    "sim_B = xr.concat([x.to_xarray()['runup'].groupby('time.year').max(dim='time') for x in l_sims_CC], 'n_sim')\n",
    "\n",
    "# Return Period historical vs. simulations\n",
    "Plot_ReturnPeriodValidation_v2(hist_A, sim_A, sim_B);\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
